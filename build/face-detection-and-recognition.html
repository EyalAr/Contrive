<html>
<head>
	<title>Face Detection and Recognition (Theory and Practice)</title>
	<link rel="stylesheet" type="text/css" href="style.css">
</head>
<body>
	<h1>Face Detection and Recognition (Theory and Practice)</h1>
	<div>
		6/4/2013
	</div>
	<div>
		Eyal Arubas &lt;eyalarubas@gmail.com&gt;
	</div>
	<hr>
	<div>
		<p>OpenCV offers a good face detection and recognition <a href="http://opencv.willowgarage.com/wiki/FaceRecognition">module</a> (by <a href="http://www.bytefish.de/">Philipp
Wagner</a>). It contains algorithms which can be used to perform some cool
stuff. In this guide I will roughly explain how face detection and recognition
work; and build a demo application using OpenCV which will detect and recognize
faces. (Also, there is a nice video of the result at the end).</p>
<h1 id="theory">Theory</h1>
<h2 id="face-detection">Face Detection</h2>
<p>As can be assumed, detecting a face is simpler than recognizing a face of a
specific person. In order to be able to determine that a certain picture
contains a face (or several) we need to be able to define the general structure
of a face. Luckily human faces do not greatly differ from each other; we all
have noses, eyes, foreheads, chins and mouths; and all of these compose the
general structure of a face.</p>
<p>Consider the following 5 figures:</p>
<p><img src="images/face-detection-and-recognition/features-eyebrows.jpg" alt="Feature 1"> <img src="images/face-detection-and-recognition/features-nose.jpg" alt="Feature 2"> <img src="images/face-detection-and-recognition/haar-eyes.jpg" alt="Feature 3"> <img src="images/face-detection-and-recognition/features-mouth.jpg" alt="Feature 4">
<img src="images/face-detection-and-recognition/features-chin.jpg" alt="Feature 5"></p>
<p>Each of these figures represents a general feature of a human face. Combining
all the features together we, indeed, receive something that resembles a face.</p>
<p><img src="images/face-detection-and-recognition/haar-all.jpg" alt="All Features"></p>
<p>By determining if each of these features is similar to some part of our
picture, we can conclude if the picture contains a face or not. Notice that
this does not have to be an accurate match; we just need to know if, roughly,
each of these features corresponds to some part of the image. The technique
used for this purpose is <a href="http://en.wikipedia.org/wiki/Template_matching">Template Matching</a>.</p>
<p>By gathering statistics about which such features compose faces and how, we can
train our algorithm to use the right features in the right positions; and thus
detect faces.</p>
<p>Let&#39;s see an example. See in the figures below how the above features can be
used to detect a face (namely, the face of President Barack Obama).</p>
<p><img src="images/face-detection-and-recognition/obama-color.jpg" alt="Obama Color"> <img src="images/face-detection-and-recognition/obama-binary.jpg" alt="Obama Binary"> <img src="images/face-detection-and-recognition/haar-features-all-obama.jpg" alt="Obama Features"></p>
<p>In order for this process be quick, we design it in such a way that we first
check the coarse features which represent the coarse structure of a face; and
only if these features match, we continue to the next iteration and use finer
features. In each such iteration we can quickly reject areas of the picture
which do not match a face, and keep checking those which we are not sure about.
In every iteration we increase the certainty that the checked area is indeed a
face, until finally we stop and make our determination.</p>
<p>In other words, rather than determining if the image does contain a face, we
can more quickly determine if the image does not contain a face; because
eliminations can be done quickly, while acceptance of faces will require more
time. We call such a process a cascading process.</p>
<p>The method depicted here is an over-simplified description of the <a href="http://en.wikipedia.org/wiki/ViolaâJones_object_detection_framework">Viola-Jones
method</a> (also known as Haar cascades). A very nice visualization of this
method can be seen in the following video by Adam Harvey.</p>
<iframe src="//player.vimeo.com/video/12774628" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>

<h2 id="face-recognition">Face Recognition</h2>
<p>The difference between face detection and recognition is that in detection we
just need to determine if there is some face in the image, but in recognition
we want to determine whose face it is. In the above example we <em>detected</em> a
face, which we <em>recognize</em> as President Obama.</p>
<p>In order to understand the methods for recognizing faces, more advanced
mathematical knowledge is required; namely linear algebra and statistics.</p>
<p>OpenCV provides three methods of face recognition: Eigenfaces, Fisherfaces and
Local Binary Patterns Histograms (LBPH).</p>
<p>All three methods perform the recognition by comparing the face to be
recognized with some training set of known faces. In the training set, we
supply the algorithm faces and tell it to which person they belong. When the
algorithm is asked to recognize some unknown face, it uses the training set to
make the recognition. Each of the three aforementioned methods uses the
training set a bit differently.</p>
<p>Eigenfaces and Fisherfaces find a mathematical description of the most dominant
features of the training set as a whole. LBPH analyzes each face in the
training set separately and independently.</p>
<p>An example training set:<br><img src="images/face-detection-and-recognition/training_set.jpg" alt="Example Training Set"></p>
<h3 id="eigenfaces-fisherfaces">Eigenfaces &amp; Fisherfaces</h3>
<p>Those familiar with linear algebra will remember that every vector space has
an orthogonal basis. By combining elements of this basis we can compose every
vector in this vector space. And vice versa, every vector in the vector space
can be decomposed to the elements of the basis.</p>
<p>Images (grayscale) are nothing more than a series of numbers, each number
corresponding to some intensity level. So why not treat images as vectors? Say,
for example, we have a collection of face images of size 150 by 150 pixels;
each of these images can be thought of as a vector of size 22,500 (150*150).
We can now talk about the vector space in which these vectors reside. By
treating the images as samples of data, we can perform a <a href="https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors#Principal_components_analysis">Principal Components
Analysis</a> and obtain the eigenvectors which make up the basis of the vector
space.</p>
<p><img src="images/face-detection-and-recognition/princomp.png" alt="Principal componenets of a dataset"><br>Principal components of a dataset (Source: <a href="https://en.wikipedia.org/wiki/File:GaussianScatterPCA.png">Wikipedia</a>).</p>
<p>These eigenvectors represent the most prominent features of the dataset, and
since we talk about face images, the eigenvectors actually represent the
strongest characteristics of the faces in the dataset. See for example the
first 8 eigenvectors of the dataset from above:</p>
<p><img src="images/face-detection-and-recognition/eigenfaces.jpg" alt="First 8 eigenfaces of the training set"><br>(To extract the eigenfaces of the training set I wrote a small Matlab script
which can be <a href="https://gist.github.com/EyalAr/5196200">obtained here</a>).</p>
<p>Now, whenever we are provided with a new, unknown, face, we can decompose it to
the basis we found, see which eigenvector(s) “explain” most of the face, and
thus determine to which person it belongs.</p>
<h3 id="local-binary-patterns-histogram">Local Binary Patterns Histogram</h3>
<p>The <a href="http://en.wikipedia.org/wiki/Local_binary_patterns">LBPH</a> method takes a different approach than the eigenfaces method.
In LBPH each images is analyzed independently, while the eigenfaces method
looks at the dataset as a whole. The LBPH method is somewhat simpler, in the
sense that we characterize each image in the dataset locally; and when a new
unknown image is provided, we perform the same analysis on it and compare the
result to each of the images in the dataset. The way which we analyze the
images is by characterizing the local patterns in each location in the image.</p>
<p>Following is such a <a href="http://en.wikipedia.org/wiki/Local_binary_patterns">local binary patterns</a> analysis on each of the images
of the dataset from above:</p>
<p><img src="images/face-detection-and-recognition/lbp.jpg" alt="Local binary patterns of the 10 images in the training set"><br>(To extract the local binary patterns of the training set I used this <a href="http://www.mathworks.com/matlabcentral/fileexchange/36484-local-binary-patterns">Matlab
script</a>).</p>
<h1 id="demo-application">Demo Application</h1>
<p>For the purpose of this guide, and to make it interesting, we will build an
application which given a video file and a person, seeks this person in the
video. Formally, we define the following inputs and outputs of our application:</p>
<p><strong>Inputs:</strong></p>
<ol>
<li>A video file.</li>
<li>A person. We need around 10 different images of this person&#39;s face in
order to be able to recognize him/her. We will use the dataset of the
faces of President Barack Obama presented earlier.</li>
</ol>
<p><strong>Outputs:</strong></p>
<ol>
<li>A video file which is identical to the original video, except that
the face of the recognized person is in a green circle, and
unrecognized faces in red circles.</li>
<li>A CSV file which gives the recognition confidence for each recognized
face in each frame of the video.</li>
</ol>
<h2 id="the-plan">The Plan</h2>
<p>Before we start coding, we better understand the different components in our
application.</p>
<p>As was already mentioned, our goal is to determine in which frames of the video
our chosen person appears. We also want to create two output files, a video in
which the faces are circled in green or red (depending upon the person to which
the face belongs), and a CSV file with the confidence level of each face in
each frame. For this, I propose the following scheme:</p>
<ol>
<li>Read the next frame of the input video.</li>
<li>Detect all the faces in the frame.</li>
<li>Try to recognize each of the detected faces as our chosen person.</li>
<li>If successful, draw a green circle around the face. Otherwise, draw a
red circle.</li>
<li>Write the confidence level of each face in the frame to a CSV file.</li>
<li>Repeat steps 1-5 until no more frames in the input video.</li>
</ol>
<p>Evidently, our application should have the following major components:</p>
<ol>
<li>Frames reader.</li>
<li>Faces detector.</li>
<li>Person recognizer.</li>
<li>Frames writer.</li>
<li>CSV writer.</li>
</ol>
<p>Each of these components will be expanded in the following sections.</p>
<p><strong>Note:</strong><br>In order to simplify this guide, we will do only frontal faces detection.</p>
<h2 id="the-code">The Code</h2>
<p>The full code of the application can be obtained in <a href="https://bitbucket.org/EyalAr/person-recognizer">this git repository</a>
(It&#39;s a <a href="opencv-installation-on-windows-netbeans-mingw.markdown">Netbeans project</a> which you can load directly to your
<a href="https://netbeans.org/">Netbeans IDE</a>).</p>
<h3 id="faces-detector">Faces Detector</h3>
<pre><code><span class="hljs-preprocessor">#!c++</span>
<span class="hljs-keyword">class</span> FaceDetector {
<span class="hljs-keyword">public</span>:
    FaceDetector(
            <span class="hljs-keyword">const</span> <span class="hljs-built_in">string</span> &amp;cascadePath,
            <span class="hljs-keyword">double</span> scaleFactor,
            <span class="hljs-keyword">int</span>    minNeighbors,
            <span class="hljs-keyword">double</span> minSizeRatio,
            <span class="hljs-keyword">double</span> maxSizeRatio);
    <span class="hljs-keyword">virtual</span> ~FaceDetector();
    <span class="hljs-keyword">void</span> findFacesInImage(<span class="hljs-keyword">const</span> Mat &amp;img, <span class="hljs-stl_container"><span class="hljs-built_in">vector</span>&lt;Rect&gt;</span> &amp;res);
<span class="hljs-keyword">private</span>:
    CascadeClassifier _cascade;
    <span class="hljs-keyword">double</span> _scaleFactor;
    <span class="hljs-keyword">int</span>    _minNeighbors;
    <span class="hljs-keyword">double</span> _minSizeRatio;
    <span class="hljs-keyword">double</span> _maxSizeRatio;
};
</code></pre><p>As explained earlier in this guide, we use the Haar cascades method to do the
detection. OpenCV provides the <code>CascadeClassifier</code> object for this purpose,
which I recommend reading about (<a href="http://docs.opencv.org/modules/objdetect/doc/cascade_classification.html">Here</a>).</p>
<p>In the <code>FaceDetector</code> class of our application we implement a method
<code>findFacesInImage</code> which, given an image, returns the rectangular coordinates
of all faces in it. Note that in this application we detect only frontal faces.
Implementing detection of profiles and faces from other angles is very similar
and straightforward.</p>
<h3 id="person-recognizer">Person Recognizer</h3>
<pre><code><span class="hljs-preprocessor">#!c++</span>
<span class="hljs-keyword">class</span> PersonRecognizer {
<span class="hljs-keyword">public</span>:
    PersonRecognizer(<span class="hljs-keyword">const</span> <span class="hljs-stl_container"><span class="hljs-built_in">vector</span>&lt;Mat&gt;</span> &amp;imgs, <span class="hljs-keyword">int</span> radius, <span class="hljs-keyword">int</span> neighbors,
            <span class="hljs-keyword">int</span> grid_x, <span class="hljs-keyword">int</span> grid_y, <span class="hljs-keyword">double</span> threshold);
    <span class="hljs-keyword">virtual</span> ~PersonRecognizer();
    <span class="hljs-keyword">bool</span> recognize(<span class="hljs-keyword">const</span> Mat &amp;face, <span class="hljs-keyword">double</span> &amp;confidence) <span class="hljs-keyword">const</span>;
<span class="hljs-keyword">private</span>:
    Ptr&lt;FaceRecognizer&gt; _model;
    Size _faceSize;
};
</code></pre><p>Following the explanation about face recognition, we will be using the LBPH
method. We will use OpenCV&#39;s <a href="http://docs.opencv.org/trunk/modules/contrib/doc/facerec/facerec_api.html"><code>FaceRecognizer</code></a> module. Look at the <a href="https://bitbucket.org/EyalAr/person-recognizer">full
code</a> to see the specifics of the implementation. The <code>PersonRecognizer</code>
class is trained (upon construction) to recognize a specific person, by
receiving a vector of faces which belong to this person. In the code you will
see the implementation of the <code>recognize</code> method, which given an image of a
face will determine if this is the person the class was trained to recognize.
The method returns a Boolean value according to the result of the recognition,
and if there was recognition, the confidence is stored in the <code>confidence</code>
variable.</p>
<h3 id="frames-reader">Frames Reader</h3>
<p>Luckily, OpenCV offers a good library for handling video files, which we will
wrap with our own interface.</p>
<p>We define the following class:</p>
<pre><code><span class="hljs-shebang">#!c++</span>
<span class="hljs-keyword">class</span> FramesReader
{
<span class="hljs-keyword">public</span>:
    FramesReader(<span class="hljs-keyword">const</span> <span class="hljs-built_in">string</span> &amp;vidPath, <span class="hljs-keyword">int</span> startFrame, <span class="hljs-keyword">int</span> endFrame, <span class="hljs-keyword">int</span> delta);
    virtual ~FramesReader();
    <span class="hljs-built_in">bool</span> getNext(Mat &amp;frame);
    Size getSize();
<span class="hljs-keyword">private</span>:
    VideoCapture _vid;
    <span class="hljs-keyword">int</span> _endFrame,
        _delta;
};
</code></pre><p>We use the <code>getNext</code> method to obtain the next frame in the video, and
<code>getSize</code> to obtain the size of the frame (in pixels).</p>
<h3 id="frames-writer">Frames Writer</h3>
<p>We define the following class, which is self explanatory:</p>
<pre><code><span class="hljs-shebang">#!c++</span>
<span class="hljs-keyword">class</span> FramesWriter
{
<span class="hljs-keyword">public</span>:
    FramesWriter(<span class="hljs-keyword">const</span> <span class="hljs-built_in">string</span> vidPath, <span class="hljs-built_in">double</span> fps, Size size, <span class="hljs-keyword">int</span> fourcc);
    virtual ~FramesWriter();
    <span class="hljs-keyword">void</span> write(Mat &amp;frame);
<span class="hljs-keyword">private</span>:
    VideoWriter _vid;
    Size _f_size;
};
</code></pre><h3 id="csv-writer">CSV Writer</h3>
<pre><code><span class="hljs-shebang">#!c++</span>
<span class="hljs-keyword">class</span> CsvWriter {
<span class="hljs-keyword">public</span>:
    CsvWriter(<span class="hljs-keyword">const</span> <span class="hljs-built_in">string</span> &amp;csvPath);
    virtual ~CsvWriter();
    <span class="hljs-keyword">void</span> nextLine();
    <span class="hljs-keyword">void</span> addEntry(<span class="hljs-keyword">const</span> <span class="hljs-built_in">string</span> &amp;s);
<span class="hljs-keyword">private</span>:
    ofstream _fs;
    <span class="hljs-built_in">bool</span> _isFirstEntry;
};
</code></pre><h2 id="results">Results</h2>
<p>In order to test the application we run it on <a href="http://www.whitehouse.gov/photos-and-video/video/2013/03/12/president-obama-speaks-presidents-export-council-meeting">this video of President Barack
Obama</a>. We use the training set from above.</p>
<p>The resulting output video:</p>
<iframe width="640" height="360" src="//www.youtube.com/embed/CXV9R6Z0-Jw?rel=0" frameborder="0" allowfullscreen></iframe>

<p>By using the data of the CSV file, we obtain the confidence level in each frame
of the video:</p>
<p><img src="images/face-detection-and-recognition/chart-confidence-600.png" alt="Confidence of recognition of each frame"></p>
<p>By setting some threshold value, we can obtain a binary determination (yes/no)
of which frames contain the face (frontal) of President Obama:</p>
<p><img src="images/face-detection-and-recognition/chart-appearances-600.png" alt="Frontal face recognition in each frame"></p>
<p>For example, we can tell, just by looking at this analysis, that in frame 4100
President Obama does not face forward, but in frame 4600 he does:</p>
<p>Frame 4100:<br><img src="images/face-detection-and-recognition/frame4100-600.jpg" alt="Frame 4100"></p>
<p>Frame 4600:<br><img src="images/face-detection-and-recognition/frame4600-600.jpg" alt="Frame 4600"></p>
<h1 id="summary">Summary</h1>
<p>We have seen examples of both detection and recognition of faces. The theory
behind the two subjects is quite interesting. The OpenCV library implements for
us the major algorithms used for these tasks.</p>
<p>By employing OpenCV we built an example application which is capable of
recognizing a specific person in a video, which might also contain other
people. The application successfully recognized where in the video our chosen
person (President Obama) faces towards the camera.</p>
<p>As was mentioned, the application was trained to recognize and detect only
frontal faces, but it can be easily extended to recognize and detect faces in
more angles and positions.</p>

	</div>
</body>
</html>